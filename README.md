# IBM-DataScienceCapstone

## Description
The IBM Data Science Capstone Project repository for the IBM Data Science Professional Certificate through Coursera. Project utilizes web based data from SpaceX Falcon9 rocket launches to analyze data for significant features and build a machine learning model that aims to predict the likelihood and determine the cost of a successful launch.

### Files

The following files are included with this project:

* `part_1a_spacex_data_collection_api.ipynb`: a Juptyer Notebook file containing the retreival of SpaceX API data
* `part_1b_spacex_webscraping.ipynb`: a Juptyer Notebook file containing the retreival of SpaceX Wiki data with webscraping
* `part_2_spacex_data_wrangling.ipynb`: a Juptyer Notebook file containing data cleaning and wrangling methods
* `part_3a_spacex_sql_eda.ipynb`: a Juptyer Notebook file containing SQL queries of SpaceX data
* `part_3b_eda_dataviz.ipynb`: a Juptyer Notebook file containing charts and visulization of SpaceX feature relationships
* `part_4a_launch_site_location.ipynb`: a Juptyer Notebook file containing a Folium map that displays SpaceX launch site locations and outcomes for that site
* `part_4b_spacex_dash_app.py`: a Python file containing the code for a Plotly Dash interactive analytical dashboard application
* `part_5_spacex_machine_learning_prediction.ipynb`: a Juptyer Notebook file containing machine learning techniques to perform predictive analysis of SpaceX launch outcomes
* `dataset_part_1a.csv`: a `.csv` file containing the SpaceX API data from `part_1a_spacex_data_collection_api.ipynb`
* `spacex_web_scraped_part_1b.csv`: a `.csv` file containing the webscraped SpaceX Wiki data from `part_1b_spacex_webscraping.ipynb`
* `dataset_part_2.csv`: a `.csv` file containing the cleaned and wrangled dataset from `part_2_spacex_data_wrangling.ipynb`
* `dataset_part_3b.csv`: a `.csv` file containing the encoded features from `part_3b_eda_dataviz.ipynb`
* `spacex_final_report.pdf`: a `.pdf` file containing the detailed analytical presentation and project findings

## Goals

1. Retrieve web sourced datasets
2. Clean, wrangle, and encode data into distinct target and feature datasets
3. Perform exploratory data analysis with SQL and visualizations
4. Create interactive analytics dashboard and Folium map
5. Perform predictive analysis using supervised machine learning on transformed datasets
6. Develop key insights from current data regarding determinant factors to launch success
7. Address potential project limitations and opportunities for further expansion

## Contributors

Hannah Ostoja -- h.ostcode@outlook.com
